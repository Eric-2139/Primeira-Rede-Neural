{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # define a conversão da imagem para tensor\n",
    "\n",
    "train_set = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte de treino do dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n",
    "\n",
    "val_set = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # Carrega a parte de validação do dataset\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a36a8834d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "imagens, etiquetas = next(data_iter)\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape) # verificar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape) # verificar as dimensões do tensor de cada etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligam a 64\n",
    "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligam a 10\n",
    "        # para a camada de saída não é necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
    "        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
    "        X = self.linear3(X) # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, train_loader, device):\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a política de atualização dos pesos e da bias\n",
    "    inicio = time() # timer para sabermos quanto levou o treino\n",
    "\n",
    "    criterio = nn.NLLLoss() # definindo o critério para calcular a perda\n",
    "    EPOCHS = 10 # número de epochs que o algoritmo rodará\n",
    "    modelo.train() # ativando o modo de treinamento do modelo\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 # inicialização da perda acumulada da epoch em questão\n",
    "\n",
    "        for imagens, etiquetas in train_loader:\n",
    "\n",
    "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compatíveis com a\n",
    "            otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
    "\n",
    "            perda_instantanea.backward() # back propagation a partir da perda\n",
    "\n",
    "            otimizador.step() # atualizando os pesos e as bias\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
    "\n",
    "        else:\n",
    "            print('Epoch {} - Perda Resultante: {}'.format(epoch+1, perda_acumulada/len(train_loader)))    \n",
    "    print('\\ntempi de treino (em minutos) =', (time()-inicio)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, val_loader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "\n",
    "    for imagens, etiquetas in val_loader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem alto custo de processamento\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device)) # output do modelo em escala logaritmica\n",
    "\n",
    "            ps = torch.exp(logps) # converte output(tensor) para escala normal\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em número, no caso, o número que o modelo previu como correto\n",
    "            etiqueta_certa = etiquetas.numpy()[1]\n",
    "\n",
    "            if(etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n",
    "                conta_corretas += 1\n",
    "            conta_todas += 1\n",
    "\n",
    "    print(f'Total de imagens testadas = {conta_todas}')\n",
    "    print('\\nPrecisão do modelo = {}%'.format(conta_corretas*100/conta_todas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "modelo.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
